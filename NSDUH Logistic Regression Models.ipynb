{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is the notebook I will use to create my logistic regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%pylab inline\n",
    "import csv\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdiag_cols = ['CASEID','AMHTXRC3','AMHSVTYP','AMHTXND2','SPDYR','SPDMON','K6SCYR','K6SCMON','K6SCMAX','WHODASC2',\n",
    "              'SMIPP_U','AMDELT','AMDEYR','ATXMDEYR','ARXMDEYR','IRINSUR4','GOVTPROG',\n",
    "              'INCOME','POVERTY2','IRSEX','IRMARIT','HEALTH2','CATAG3','NEWRACE2','EDUCCAT2']\n",
    "Mental_Diagnostics = pd.read_csv('C:/Users/Cody/Downloads/NSDUH/2014/NSDUH-2014-DS0001-data/NSDUH-2014-DS0001-data-excel.tsv',usecols=mdiag_cols, sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#change to N/A for missing data\n",
    "Mental_Diagnostics.AMHTXRC3.astype('int')\n",
    "Mental_Diagnostics.AMHTXRC3.replace(int(2),int(0),inplace=True)#received any mental health trt past year\n",
    "Mental_Diagnostics.replace(-9, np.nan, inplace=True)\n",
    "Mental_Diagnostics.IRMARIT.replace(99,np.nan,inplace=True)#1-married,2-widowed,3-seperated/div,4-never married\n",
    "#change vars coded 1:yes, 2:no --> 1:yes, 0:no \n",
    "Mental_Diagnostics.AMHTXND2.replace(2,0,inplace=True)#perceived need for mental health treatment in past year\n",
    "Mental_Diagnostics.AMDELT.replace(2,0,inplace=True)#lifetime major depressive episode\n",
    "Mental_Diagnostics.AMDEYR.replace(2,0,inplace=True)#past year major depressive episode\n",
    "Mental_Diagnostics.GOVTPROG.replace(2,0,inplace=True)#participate in government assistance programs\n",
    "Mental_Diagnostics.IRINSUR4.replace(2,0,inplace=True)#1-has insurance, 0-no insurance\n",
    "Mental_Diagnostics.IRSEX.replace(2,0,inplace=True)#1-male, 0-female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mh_sample = Mental_Diagnostics[Mental_Diagnostics.SPDYR==1]\n",
    "#SPDYR = 1(subsample of 5696 adults) experienced psychological distress this past year\n",
    "#my logistic regression will apply to the population of adults who experienced severe psychological distress in the past year in the U.S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.554675\n",
       "1.0    0.445325\n",
       "Name: AMHTXRC3, dtype: float64"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbc786d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mh_sample['AMHTXRC3'].hist()\n",
    "mh_sample['AMHTXRC3'].value_counts()/mh_sample['AMHTXRC3'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_ages = pd.get_dummies(mh_sample['CATAG3'],prefix='age') # 2:18-25, 3:26-34, 4:35-49, 5:50+\n",
    "dummy_marriage = pd.get_dummies(mh_sample['IRMARIT'],prefix='marriage') # 1-married, 2-widowed, 3-sep/div, 4-unmarried\n",
    "dummy_race = pd.get_dummies(mh_sample['NEWRACE2'],prefix='race') # 1-White, 2-Black, 3-Native American, 4-Pacific Islander, 5-Asian, 6-Mixed, 7-Hispanic\n",
    "dummy_health = pd.get_dummies(mh_sample['HEALTH2'],prefix='health') # overall health(1-excellent, 2-very good, 3-good, 4-fair/poor)\n",
    "dummy_education = pd.get_dummies(mh_sample['EDUCCAT2'],prefix='education') #1-less than high school, 2-high school grad, 3-some college, 4-college graduate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMHTXRC3</th>\n",
       "      <th>AMHTXND2</th>\n",
       "      <th>WHODASC2</th>\n",
       "      <th>SMIPP_U</th>\n",
       "      <th>AMDELT</th>\n",
       "      <th>IRSEX</th>\n",
       "      <th>IRINSUR4</th>\n",
       "      <th>age_2</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_4</th>\n",
       "      <th>...</th>\n",
       "      <th>race_3</th>\n",
       "      <th>race_4</th>\n",
       "      <th>race_5</th>\n",
       "      <th>race_6</th>\n",
       "      <th>race_7</th>\n",
       "      <th>health_1.0</th>\n",
       "      <th>health_2.0</th>\n",
       "      <th>health_3.0</th>\n",
       "      <th>health_4.0</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.445332</td>\n",
       "      <td>0.294462</td>\n",
       "      <td>11.972666</td>\n",
       "      <td>0.227417</td>\n",
       "      <td>0.544551</td>\n",
       "      <td>0.349840</td>\n",
       "      <td>0.826234</td>\n",
       "      <td>0.460596</td>\n",
       "      <td>0.212460</td>\n",
       "      <td>0.212638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016862</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.036209</td>\n",
       "      <td>0.044373</td>\n",
       "      <td>0.148740</td>\n",
       "      <td>0.133475</td>\n",
       "      <td>0.337771</td>\n",
       "      <td>0.308129</td>\n",
       "      <td>0.220447</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497047</td>\n",
       "      <td>0.455841</td>\n",
       "      <td>6.245606</td>\n",
       "      <td>0.260468</td>\n",
       "      <td>0.498055</td>\n",
       "      <td>0.476962</td>\n",
       "      <td>0.378942</td>\n",
       "      <td>0.498489</td>\n",
       "      <td>0.409085</td>\n",
       "      <td>0.409210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128765</td>\n",
       "      <td>0.072783</td>\n",
       "      <td>0.186826</td>\n",
       "      <td>0.205942</td>\n",
       "      <td>0.355863</td>\n",
       "      <td>0.340118</td>\n",
       "      <td>0.472992</td>\n",
       "      <td>0.461761</td>\n",
       "      <td>0.414585</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.029295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.106492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.355731</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.929121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AMHTXRC3     AMHTXND2     WHODASC2      SMIPP_U       AMDELT  \\\n",
       "count  5634.000000  5634.000000  5634.000000  5634.000000  5634.000000   \n",
       "mean      0.445332     0.294462    11.972666     0.227417     0.544551   \n",
       "std       0.497047     0.455841     6.245606     0.260468     0.498055   \n",
       "min       0.000000     0.000000     0.000000     0.004284     0.000000   \n",
       "25%       0.000000     0.000000     8.000000     0.029295     0.000000   \n",
       "50%       0.000000     0.000000    12.000000     0.106492     1.000000   \n",
       "75%       1.000000     1.000000    16.000000     0.355731     1.000000   \n",
       "max       1.000000     1.000000    24.000000     0.929121     1.000000   \n",
       "\n",
       "             IRSEX     IRINSUR4        age_2        age_3        age_4  \\\n",
       "count  5634.000000  5634.000000  5634.000000  5634.000000  5634.000000   \n",
       "mean      0.349840     0.826234     0.460596     0.212460     0.212638   \n",
       "std       0.476962     0.378942     0.498489     0.409085     0.409210   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     1.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "         ...           race_3       race_4       race_5       race_6  \\\n",
       "count    ...      5634.000000  5634.000000  5634.000000  5634.000000   \n",
       "mean     ...         0.016862     0.005325     0.036209     0.044373   \n",
       "std      ...         0.128765     0.072783     0.186826     0.205942   \n",
       "min      ...         0.000000     0.000000     0.000000     0.000000   \n",
       "25%      ...         0.000000     0.000000     0.000000     0.000000   \n",
       "50%      ...         0.000000     0.000000     0.000000     0.000000   \n",
       "75%      ...         0.000000     0.000000     0.000000     0.000000   \n",
       "max      ...         1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "            race_7   health_1.0   health_2.0   health_3.0   health_4.0  \\\n",
       "count  5634.000000  5634.000000  5634.000000  5634.000000  5634.000000   \n",
       "mean      0.148740     0.133475     0.337771     0.308129     0.220447   \n",
       "std       0.355863     0.340118     0.472992     0.461761     0.414585   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       intercept  \n",
       "count     5634.0  \n",
       "mean         1.0  \n",
       "std          0.0  \n",
       "min          1.0  \n",
       "25%          1.0  \n",
       "50%          1.0  \n",
       "75%          1.0  \n",
       "max          1.0  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a table with just the columns I want to use for logistic regression\n",
    "cols_to_keep = ['AMHTXRC3','AMHTXND2','WHODASC2','SMIPP_U','AMDELT','IRSEX','IRINSUR4']\n",
    "data = mh_sample[cols_to_keep].copy()\n",
    "data = data.join(dummy_ages.ix[:,'age_2':])\n",
    "data = data.join(dummy_race.ix[:,'race_1':])\n",
    "data = data.join(dummy_health.ix[:,'health_1':])\n",
    "#data = data.join(dummy_education.ix[:,'education_2':])\n",
    "#data = data.join(dummy_marriage.ix[:,'marriage_2':])\n",
    "data['intercept'] = 1\n",
    "#finally realized that it was the n/a values in the data messing up my logistic regression, so I dropped the rows with N/A values\n",
    "data = data[pd.notnull(data['AMHTXRC3'])]\n",
    "data = data[pd.notnull(data['AMHTXND2'])]\n",
    "data = data[pd.notnull(data['AMDELT'])]\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now I have my table with all of the potential predictor variables\n",
    "#I am looking into a method that will select the K best predictors for my response variable AMHTXRC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cols = data.columns[1:]\n",
    "#train_cols = data['AMHTXRC3','AMHTXND2','WHODASC2','SMIPP_U','AMDELT','IRSEX','age_2','race_1','health_2.0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.570453\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cody\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "logit = sm.Logit(data['AMHTXRC3'],data[train_cols])\n",
    "result=logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#result.summary()\n",
    "#I tried to fit a model with all of the variables and the variables with the highest p-values in order are:\n",
    "#education_2, marriage_3, marriage_4, marriage_2, education_3, education_4, K6SCMAX eliminated\n",
    "#race_3, race_4, race_6, health_2, health_3\n",
    "#I will use backwards variable selection to reduce the model to something more realistic and useful\n",
    "#Update: Reduced to 8 variables(including categoricals)\n",
    "\n",
    "\n",
    "##Update : Repressed results because they include all dummy variables for categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>OR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AMHTXND2</th>\n",
       "      <td>1.294729</td>\n",
       "      <td>1.699858</td>\n",
       "      <td>1.483528e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHODASC2</th>\n",
       "      <td>1.045786</td>\n",
       "      <td>1.073605</td>\n",
       "      <td>1.059605e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMIPP_U</th>\n",
       "      <td>1.995533</td>\n",
       "      <td>3.939458</td>\n",
       "      <td>2.803805e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMDELT</th>\n",
       "      <td>1.247412</td>\n",
       "      <td>1.638623</td>\n",
       "      <td>1.429698e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRSEX</th>\n",
       "      <td>0.614719</td>\n",
       "      <td>0.791960</td>\n",
       "      <td>6.977343e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRINSUR4</th>\n",
       "      <td>1.854636</td>\n",
       "      <td>2.600402</td>\n",
       "      <td>2.196087e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.057432e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.739871e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>2.231524e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>2.698072e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.046233e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.840883e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.238077e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.439446e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.442789e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.670795e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.285947e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_1.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>6.774604e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_2.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>9.367558e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_3.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>9.586298e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_4.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.163595e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.107698e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                2.5%     97.5%            OR\n",
       "AMHTXND2    1.294729  1.699858  1.483528e+00\n",
       "WHODASC2    1.045786  1.073605  1.059605e+00\n",
       "SMIPP_U     1.995533  3.939458  2.803805e+00\n",
       "AMDELT      1.247412  1.638623  1.429698e+00\n",
       "IRSEX       0.614719  0.791960  6.977343e-01\n",
       "IRINSUR4    1.854636  2.600402  2.196087e+00\n",
       "age_2       0.000000       inf  1.057432e+01\n",
       "age_3       0.000000       inf  1.739871e+01\n",
       "age_4       0.000000       inf  2.231524e+01\n",
       "age_5       0.000000       inf  2.698072e+01\n",
       "race_1           NaN       NaN  1.046233e+01\n",
       "race_2           NaN       NaN  4.840883e+00\n",
       "race_3           NaN       NaN  5.238077e+00\n",
       "race_4           NaN       NaN  3.439446e+00\n",
       "race_5           NaN       NaN  3.442789e+00\n",
       "race_6           NaN       NaN  6.670795e+00\n",
       "race_7           NaN       NaN  5.285947e+00\n",
       "health_1.0  0.000000       inf  6.774604e-09\n",
       "health_2.0  0.000000       inf  9.367558e-09\n",
       "health_3.0  0.000000       inf  9.586298e-09\n",
       "health_4.0  0.000000       inf  1.163595e-08\n",
       "intercept   0.000000       inf  1.107698e+05"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = result.params\n",
    "conf = result.conf_int()\n",
    "conf['OR'] = params\n",
    "conf.columns = ['2.5%','97.5%','OR']\n",
    "np.exp(conf)\n",
    "#the table below shows us the 95% confidence interval for the odds ratios of each predictor\n",
    "#this is the odds ratio for receiving treatment for those with serious psychological distress in the past year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_to_keep = ['AMHTXRC3','WHODASC2','AMDELT','IRSEX']\n",
    "data2 = mh_sample[cols_to_keep].copy()\n",
    "data2 = data2.join(dummy_ages.ix[:,'age_3':])\n",
    "data2 = data2.join(dummy_race.ix[:,'race_2':])\n",
    "data2 = data2.join(dummy_health.ix[:,'health_2':])\n",
    "data2['intercept'] = 1\n",
    "data2 = data2[pd.notnull(data2['AMHTXRC3'])]\n",
    "data2 = data2[pd.notnull(data2['AMDELT'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_cols = data2.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.585997\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "logit = sm.Logit(data2['AMHTXRC3'],data2[train_cols])\n",
    "result=logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>AMHTXRC3</td>     <th>  No. Observations:  </th>   <td>  5646</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  5630</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>    15</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 17 Aug 2016</td> <th>  Pseudo R-squ.:     </th>   <td>0.1472</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>15:18:11</td>     <th>  Log-Likelihood:    </th>  <td> -3308.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -3879.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>3.474e-234</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WHODASC2</th>   <td>    0.0856</td> <td>    0.005</td> <td>   15.749</td> <td> 0.000</td> <td>    0.075     0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AMDELT</th>     <td>    0.5546</td> <td>    0.064</td> <td>    8.668</td> <td> 0.000</td> <td>    0.429     0.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IRSEX</th>      <td>   -0.3835</td> <td>    0.063</td> <td>   -6.073</td> <td> 0.000</td> <td>   -0.507    -0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_3</th>      <td>    0.4816</td> <td>    0.077</td> <td>    6.236</td> <td> 0.000</td> <td>    0.330     0.633</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_4</th>      <td>    0.7673</td> <td>    0.079</td> <td>    9.716</td> <td> 0.000</td> <td>    0.613     0.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_5</th>      <td>    0.9876</td> <td>    0.103</td> <td>    9.614</td> <td> 0.000</td> <td>    0.786     1.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race_2</th>     <td>   -0.7433</td> <td>    0.104</td> <td>   -7.125</td> <td> 0.000</td> <td>   -0.948    -0.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race_3</th>     <td>   -0.6614</td> <td>    0.240</td> <td>   -2.759</td> <td> 0.006</td> <td>   -1.131    -0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race_4</th>     <td>   -1.2086</td> <td>    0.461</td> <td>   -2.621</td> <td> 0.009</td> <td>   -2.113    -0.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race_5</th>     <td>   -1.0788</td> <td>    0.185</td> <td>   -5.841</td> <td> 0.000</td> <td>   -1.441    -0.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race_6</th>     <td>   -0.4105</td> <td>    0.146</td> <td>   -2.810</td> <td> 0.005</td> <td>   -0.697    -0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race_7</th>     <td>   -0.7462</td> <td>    0.089</td> <td>   -8.370</td> <td> 0.000</td> <td>   -0.921    -0.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>health_2.0</th> <td>    0.3354</td> <td>    0.099</td> <td>    3.382</td> <td> 0.001</td> <td>    0.141     0.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>health_3.0</th> <td>    0.3461</td> <td>    0.101</td> <td>    3.443</td> <td> 0.001</td> <td>    0.149     0.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>health_4.0</th> <td>    0.5796</td> <td>    0.109</td> <td>    5.299</td> <td> 0.000</td> <td>    0.365     0.794</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>  <td>   -1.9307</td> <td>    0.115</td> <td>  -16.852</td> <td> 0.000</td> <td>   -2.155    -1.706</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               AMHTXRC3   No. Observations:                 5646\n",
       "Model:                          Logit   Df Residuals:                     5630\n",
       "Method:                           MLE   Df Model:                           15\n",
       "Date:                Wed, 17 Aug 2016   Pseudo R-squ.:                  0.1472\n",
       "Time:                        15:18:11   Log-Likelihood:                -3308.5\n",
       "converged:                       True   LL-Null:                       -3879.8\n",
       "                                        LLR p-value:                3.474e-234\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "WHODASC2       0.0856      0.005     15.749      0.000         0.075     0.096\n",
       "AMDELT         0.5546      0.064      8.668      0.000         0.429     0.680\n",
       "IRSEX         -0.3835      0.063     -6.073      0.000        -0.507    -0.260\n",
       "age_3          0.4816      0.077      6.236      0.000         0.330     0.633\n",
       "age_4          0.7673      0.079      9.716      0.000         0.613     0.922\n",
       "age_5          0.9876      0.103      9.614      0.000         0.786     1.189\n",
       "race_2        -0.7433      0.104     -7.125      0.000        -0.948    -0.539\n",
       "race_3        -0.6614      0.240     -2.759      0.006        -1.131    -0.192\n",
       "race_4        -1.2086      0.461     -2.621      0.009        -2.113    -0.305\n",
       "race_5        -1.0788      0.185     -5.841      0.000        -1.441    -0.717\n",
       "race_6        -0.4105      0.146     -2.810      0.005        -0.697    -0.124\n",
       "race_7        -0.7462      0.089     -8.370      0.000        -0.921    -0.571\n",
       "health_2.0     0.3354      0.099      3.382      0.001         0.141     0.530\n",
       "health_3.0     0.3461      0.101      3.443      0.001         0.149     0.543\n",
       "health_4.0     0.5796      0.109      5.299      0.000         0.365     0.794\n",
       "intercept     -1.9307      0.115    -16.852      0.000        -2.155    -1.706\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>OR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WHODASC2</th>\n",
       "      <td>1.077792</td>\n",
       "      <td>1.100992</td>\n",
       "      <td>1.089330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMDELT</th>\n",
       "      <td>1.536030</td>\n",
       "      <td>1.973886</td>\n",
       "      <td>1.741249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRSEX</th>\n",
       "      <td>0.602143</td>\n",
       "      <td>0.771250</td>\n",
       "      <td>0.681471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_3</th>\n",
       "      <td>1.391297</td>\n",
       "      <td>1.883183</td>\n",
       "      <td>1.618662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_4</th>\n",
       "      <td>1.845142</td>\n",
       "      <td>2.514626</td>\n",
       "      <td>2.154029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_5</th>\n",
       "      <td>2.195182</td>\n",
       "      <td>3.283601</td>\n",
       "      <td>2.684791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_2</th>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.475533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_3</th>\n",
       "      <td>0.322619</td>\n",
       "      <td>0.825659</td>\n",
       "      <td>0.516114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_4</th>\n",
       "      <td>0.120930</td>\n",
       "      <td>0.737333</td>\n",
       "      <td>0.298606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_5</th>\n",
       "      <td>0.236753</td>\n",
       "      <td>0.488316</td>\n",
       "      <td>0.340015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_6</th>\n",
       "      <td>0.498151</td>\n",
       "      <td>0.883255</td>\n",
       "      <td>0.663321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_7</th>\n",
       "      <td>0.398162</td>\n",
       "      <td>0.564716</td>\n",
       "      <td>0.474182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_2.0</th>\n",
       "      <td>1.151458</td>\n",
       "      <td>1.698470</td>\n",
       "      <td>1.398469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_3.0</th>\n",
       "      <td>1.160758</td>\n",
       "      <td>1.721478</td>\n",
       "      <td>1.413584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_4.0</th>\n",
       "      <td>1.440842</td>\n",
       "      <td>2.212251</td>\n",
       "      <td>1.785358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>0.115880</td>\n",
       "      <td>0.181571</td>\n",
       "      <td>0.145053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                2.5%     97.5%        OR\n",
       "WHODASC2    1.077792  1.100992  1.089330\n",
       "AMDELT      1.536030  1.973886  1.741249\n",
       "IRSEX       0.602143  0.771250  0.681471\n",
       "age_3       1.391297  1.883183  1.618662\n",
       "age_4       1.845142  2.514626  2.154029\n",
       "age_5       2.195182  3.283601  2.684791\n",
       "race_2      0.387600  0.583417  0.475533\n",
       "race_3      0.322619  0.825659  0.516114\n",
       "race_4      0.120930  0.737333  0.298606\n",
       "race_5      0.236753  0.488316  0.340015\n",
       "race_6      0.498151  0.883255  0.663321\n",
       "race_7      0.398162  0.564716  0.474182\n",
       "health_2.0  1.151458  1.698470  1.398469\n",
       "health_3.0  1.160758  1.721478  1.413584\n",
       "health_4.0  1.440842  2.212251  1.785358\n",
       "intercept   0.115880  0.181571  0.145053"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = result.params\n",
    "conf = result.conf_int()\n",
    "conf['OR'] = params\n",
    "conf.columns = ['2.5%','97.5%','OR']\n",
    "np.exp(conf)\n",
    "#the table below shows us the 95% confidence interval for the odds ratios of each predictor\n",
    "#this is the odds ratio for receiving treatment for those with serious psychological distress in the past year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def cv_score(clf, x, y, score_func=accuracy_score):\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    for train, test in KFold(y.size, nfold): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y[train]) # fit\n",
    "        result += score_func(clf.predict(x[test]), y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average\n",
    "\n",
    "#I imported the important functions from sklearn to split my data into training and test data,\n",
    "#initialize a logistic regression model, perform cross-validation, and score the accuracy of the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(data[['AMHTXND2','WHODASC2','SMIPP_U','AMDELT','IRSEX','age_3','age_4','age_5','race_2','race_3','race_4','race_5','race_6','race_7',\n",
    "                                                    'health_2.0','health_3.0','health_4.0']].values, \n",
    "                                              (data['AMHTXRC3'] == 1).values,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693399574166\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(Xlr,ylr)\n",
    "print (accuracy_score(clf.predict(Xtestlr),ytestlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687810650888\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "score = cv_score(clf, Xlr, ylr)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C value: 0.1\n",
      "Average Score using this C: 0.690177514793\n"
     ]
    }
   ],
   "source": [
    "#the grid of parameters to search over\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "max_score = 0\n",
    "\n",
    "#your turn\n",
    "for C in Cs :\n",
    "    clf = LogisticRegression(C=C)\n",
    "    score = cv_score(clf, Xlr, ylr)\n",
    "    \n",
    "    if score > max_score :\n",
    "        max_score = score\n",
    "        bestC = C\n",
    "        \n",
    "print(\"Best C value:\",bestC)\n",
    "print(\"Average Score using this C:\",max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69836763662171752"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfBest = LogisticRegression(C=bestC)\n",
    "clfBest.fit(Xlr,ylr)\n",
    "ypred = clfBest.predict(Xtestlr)\n",
    "accuracy_score(ypred,ytestlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_classify(clf, parameters, indf, featurenames, targetname, target1val, standardize=False, train_size=0.8):\n",
    "    subdf=indf[featurenames]\n",
    "    if standardize:\n",
    "        subdfstd=(subdf - subdf.mean())/subdf.std()\n",
    "    else:\n",
    "        subdfstd=subdf\n",
    "    X=subdfstd.values\n",
    "    y=(indf[targetname].values==target1val)*1\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=train_size)\n",
    "    clf = cv_optimize(clf, parameters, Xtrain, ytrain)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print (\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "    print (\"Accuracy on test data:     %0.2f\" % (test_accuracy))\n",
    "    return clf, Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=5):\n",
    "    gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
    "    gs.fit(Xtrain, ytrain)\n",
    "    print (\"BEST PARAMS\", gs.best_params_)\n",
    "    best = gs.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 1}\n",
      "Accuracy on training data: 0.69\n",
      "Accuracy on test data:     0.71\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['AMHTXND2','WHODASC2','SMIPP_U','AMDELT','IRSEX','age_3','age_4','age_5','race_2','race_3','race_4','race_5','race_6','race_7',\n",
    "                                                    'health_2.0','health_3.0','health_4.0'], 'AMHTXRC3',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(data[['AMHTXND2','WHODASC2','SMIPP_U','AMDELT','IRSEX','age_2','race_1','race_2','race_7',\n",
    "                                                    ]].values, \n",
    "                                              (data['AMHTXRC3'] == 1).values,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.694109297374\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(Xlr,ylr)\n",
    "print (accuracy_score(clf.predict(Xtestlr),ytestlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685917159763\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "score = cv_score(clf, Xlr, ylr)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C value: 1\n",
      "Average Score using this C: 0.685917159763\n"
     ]
    }
   ],
   "source": [
    "#the grid of parameters to search over\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "max_score = 0\n",
    "\n",
    "for C in Cs :\n",
    "    clf = LogisticRegression(C=C)\n",
    "    score = cv_score(clf, Xlr, ylr)\n",
    "    \n",
    "    if score > max_score :\n",
    "        max_score = score\n",
    "        bestC = C\n",
    "        \n",
    "print(\"Best C value:\",bestC)\n",
    "print(\"Average Score using this C:\",max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69410929737402416"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfBest = LogisticRegression(C=bestC)\n",
    "clfBest.fit(Xlr,ylr)\n",
    "ypred = clfBest.predict(Xtestlr)\n",
    "accuracy_score(ypred,ytestlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 100}\n",
      "Accuracy on training data: 0.69\n",
      "Accuracy on test data:     0.69\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['AMHTXND2','WHODASC2','SMIPP_U','AMDELT','IRSEX','age_2','race_1','race_2','race_7'], 'AMHTXRC3',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mean_squared_error(ypred,ytestlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = list(range(0,17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef_table = pd.DataFrame(clf.coef_,columns=['AMHTXND2','WHODASC2','SMIPP_U','AMDELT','IRSEX','age_3','age_4','age_5','race_2','race_3','race_4','race_5','race_6','race_7',\n",
    "                                                    'health_2.0','health_3.0','health_4.0'], index=['Coefficients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AMHTXND2</th>\n",
       "      <td>0.300346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHODASC2</th>\n",
       "      <td>0.061183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMIPP_U</th>\n",
       "      <td>0.981382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMDELT</th>\n",
       "      <td>0.377490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRSEX</th>\n",
       "      <td>-0.325137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_3</th>\n",
       "      <td>0.432341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_4</th>\n",
       "      <td>0.669456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_5</th>\n",
       "      <td>1.047469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_2</th>\n",
       "      <td>-0.804206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_3</th>\n",
       "      <td>-0.487379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_4</th>\n",
       "      <td>-0.666179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_5</th>\n",
       "      <td>-1.028038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_6</th>\n",
       "      <td>-0.430177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_7</th>\n",
       "      <td>-0.686019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_2.0</th>\n",
       "      <td>0.165227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_3.0</th>\n",
       "      <td>0.227144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_4.0</th>\n",
       "      <td>0.372580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coefficients\n",
       "AMHTXND2        0.300346\n",
       "WHODASC2        0.061183\n",
       "SMIPP_U         0.981382\n",
       "AMDELT          0.377490\n",
       "IRSEX          -0.325137\n",
       "age_3           0.432341\n",
       "age_4           0.669456\n",
       "age_5           1.047469\n",
       "race_2         -0.804206\n",
       "race_3         -0.487379\n",
       "race_4         -0.666179\n",
       "race_5         -1.028038\n",
       "race_6         -0.430177\n",
       "race_7         -0.686019\n",
       "health_2.0      0.165227\n",
       "health_3.0      0.227144\n",
       "health_4.0      0.372580"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_table.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMHTXND2</th>\n",
       "      <th>WHODASC2</th>\n",
       "      <th>SMIPP_U</th>\n",
       "      <th>AMDELT</th>\n",
       "      <th>IRSEX</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_4</th>\n",
       "      <th>age_5</th>\n",
       "      <th>race_2</th>\n",
       "      <th>race_3</th>\n",
       "      <th>race_4</th>\n",
       "      <th>race_5</th>\n",
       "      <th>race_6</th>\n",
       "      <th>race_7</th>\n",
       "      <th>health_2.0</th>\n",
       "      <th>health_3.0</th>\n",
       "      <th>health_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "      <td>5634.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.294462</td>\n",
       "      <td>11.972666</td>\n",
       "      <td>0.227417</td>\n",
       "      <td>0.544551</td>\n",
       "      <td>0.349840</td>\n",
       "      <td>0.212460</td>\n",
       "      <td>0.212638</td>\n",
       "      <td>0.114306</td>\n",
       "      <td>0.102946</td>\n",
       "      <td>0.016862</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.036209</td>\n",
       "      <td>0.044373</td>\n",
       "      <td>0.148740</td>\n",
       "      <td>0.337771</td>\n",
       "      <td>0.308129</td>\n",
       "      <td>0.220447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.455841</td>\n",
       "      <td>6.245606</td>\n",
       "      <td>0.260468</td>\n",
       "      <td>0.498055</td>\n",
       "      <td>0.476962</td>\n",
       "      <td>0.409085</td>\n",
       "      <td>0.409210</td>\n",
       "      <td>0.318211</td>\n",
       "      <td>0.303916</td>\n",
       "      <td>0.128765</td>\n",
       "      <td>0.072783</td>\n",
       "      <td>0.186826</td>\n",
       "      <td>0.205942</td>\n",
       "      <td>0.355863</td>\n",
       "      <td>0.472992</td>\n",
       "      <td>0.461761</td>\n",
       "      <td>0.414585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.029295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.106492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.355731</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.929121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AMHTXND2     WHODASC2      SMIPP_U       AMDELT        IRSEX  \\\n",
       "count  5634.000000  5634.000000  5634.000000  5634.000000  5634.000000   \n",
       "mean      0.294462    11.972666     0.227417     0.544551     0.349840   \n",
       "std       0.455841     6.245606     0.260468     0.498055     0.476962   \n",
       "min       0.000000     0.000000     0.004284     0.000000     0.000000   \n",
       "25%       0.000000     8.000000     0.029295     0.000000     0.000000   \n",
       "50%       0.000000    12.000000     0.106492     1.000000     0.000000   \n",
       "75%       1.000000    16.000000     0.355731     1.000000     1.000000   \n",
       "max       1.000000    24.000000     0.929121     1.000000     1.000000   \n",
       "\n",
       "             age_3        age_4        age_5       race_2       race_3  \\\n",
       "count  5634.000000  5634.000000  5634.000000  5634.000000  5634.000000   \n",
       "mean      0.212460     0.212638     0.114306     0.102946     0.016862   \n",
       "std       0.409085     0.409210     0.318211     0.303916     0.128765   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "            race_4       race_5       race_6       race_7   health_2.0  \\\n",
       "count  5634.000000  5634.000000  5634.000000  5634.000000  5634.000000   \n",
       "mean      0.005325     0.036209     0.044373     0.148740     0.337771   \n",
       "std       0.072783     0.186826     0.205942     0.355863     0.472992   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        health_3.0   health_4.0  \n",
       "count  5634.000000  5634.000000  \n",
       "mean      0.308129     0.220447  \n",
       "std       0.461761     0.414585  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.000000     0.000000  \n",
       "75%       1.000000     0.000000  \n",
       "max       1.000000     1.000000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['AMHTXND2','WHODASC2','SMIPP_U','AMDELT','IRSEX','age_3','age_4','age_5','race_2','race_3','race_4','race_5','race_6','race_7',\n",
    "                                                    'health_2.0','health_3.0','health_4.0']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = data[['AMHTXND2','WHODASC2','SMIPP_U','AMDELT','IRSEX','age_3','age_4','age_5','race_2','race_3','race_4','race_5','race_6','race_7',\n",
    "                                                    'health_2.0','health_3.0','health_4.0']].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45584108180370675"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coefficients    0.300346\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_table[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#needed to convert from an array to a list in order to put it into a dataframe\n",
    "coef_list = clf.coef_.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_list = list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.65888384494072072,\n",
       " 0.009796223423419452,\n",
       " 3.7677674602301097,\n",
       " 0.75792767377490999,\n",
       " -0.68168295081726493,\n",
       " 1.0568501615572063,\n",
       " 1.6359731163071878,\n",
       " 3.2917462811840026,\n",
       " -2.6461477869636729,\n",
       " -3.7850127942828262,\n",
       " -9.1529208415563961,\n",
       " -5.5026591764791659,\n",
       " -2.08882829376812,\n",
       " -1.92775857281184,\n",
       " 0.34932338110483913,\n",
       " 0.49190756956076992,\n",
       " 0.89868112849247173]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardize = l\n",
    "for i in range(len(l)) :\n",
    "    standardize[i] = coef_list[i]/std_list[i]\n",
    "standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3503263779305148,\n",
       " 1.063093818223835,\n",
       " 2.6681408461891456,\n",
       " 1.458618882751058,\n",
       " 0.7224286378169595,\n",
       " 1.540861207571201,\n",
       " 1.9531745204351443,\n",
       " 2.8504281281092316,\n",
       " 0.4474429679363027,\n",
       " 0.6142343818339604,\n",
       " 0.5136674289773722,\n",
       " 0.3577079706296366,\n",
       " 0.6503941013971783,\n",
       " 0.5035769834565175,\n",
       " 1.1796610325707222,\n",
       " 1.2550103907250958,\n",
       " 1.4514742815576043]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate Odds Ratio for interpretation of parameter coefficients\n",
    "OR = np.exp(coef_list).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMHTXND2</th>\n",
       "      <th>WHODASC2</th>\n",
       "      <th>SMIPP_U</th>\n",
       "      <th>AMDELT</th>\n",
       "      <th>IRSEX</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_4</th>\n",
       "      <th>age_5</th>\n",
       "      <th>race_2</th>\n",
       "      <th>race_3</th>\n",
       "      <th>race_4</th>\n",
       "      <th>race_5</th>\n",
       "      <th>race_6</th>\n",
       "      <th>race_7</th>\n",
       "      <th>health_2.0</th>\n",
       "      <th>health_3.0</th>\n",
       "      <th>health_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Coefficients</th>\n",
       "      <td>0.300346</td>\n",
       "      <td>0.061183</td>\n",
       "      <td>0.981382</td>\n",
       "      <td>0.377490</td>\n",
       "      <td>-0.325137</td>\n",
       "      <td>0.432341</td>\n",
       "      <td>0.669456</td>\n",
       "      <td>1.047469</td>\n",
       "      <td>-0.804206</td>\n",
       "      <td>-0.487379</td>\n",
       "      <td>-0.666179</td>\n",
       "      <td>-1.028038</td>\n",
       "      <td>-0.430177</td>\n",
       "      <td>-0.686019</td>\n",
       "      <td>0.165227</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.372580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Deviation</th>\n",
       "      <td>0.455841</td>\n",
       "      <td>6.245606</td>\n",
       "      <td>0.260468</td>\n",
       "      <td>0.498055</td>\n",
       "      <td>0.476962</td>\n",
       "      <td>0.409085</td>\n",
       "      <td>0.409210</td>\n",
       "      <td>0.318211</td>\n",
       "      <td>0.303916</td>\n",
       "      <td>0.128765</td>\n",
       "      <td>0.072783</td>\n",
       "      <td>0.186826</td>\n",
       "      <td>0.205942</td>\n",
       "      <td>0.355863</td>\n",
       "      <td>0.472992</td>\n",
       "      <td>0.461761</td>\n",
       "      <td>0.414585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relative Coef Size</th>\n",
       "      <td>0.658884</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>3.767767</td>\n",
       "      <td>0.757928</td>\n",
       "      <td>-0.681683</td>\n",
       "      <td>1.056850</td>\n",
       "      <td>1.635973</td>\n",
       "      <td>3.291746</td>\n",
       "      <td>-2.646148</td>\n",
       "      <td>-3.785013</td>\n",
       "      <td>-9.152921</td>\n",
       "      <td>-5.502659</td>\n",
       "      <td>-2.088828</td>\n",
       "      <td>-1.927759</td>\n",
       "      <td>0.349323</td>\n",
       "      <td>0.491908</td>\n",
       "      <td>0.898681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Odds Ratio</th>\n",
       "      <td>1.350326</td>\n",
       "      <td>1.063094</td>\n",
       "      <td>2.668141</td>\n",
       "      <td>1.458619</td>\n",
       "      <td>0.722429</td>\n",
       "      <td>1.540861</td>\n",
       "      <td>1.953175</td>\n",
       "      <td>2.850428</td>\n",
       "      <td>0.447443</td>\n",
       "      <td>0.614234</td>\n",
       "      <td>0.513667</td>\n",
       "      <td>0.357708</td>\n",
       "      <td>0.650394</td>\n",
       "      <td>0.503577</td>\n",
       "      <td>1.179661</td>\n",
       "      <td>1.255010</td>\n",
       "      <td>1.451474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    AMHTXND2  WHODASC2   SMIPP_U    AMDELT     IRSEX  \\\n",
       "Coefficients        0.300346  0.061183  0.981382  0.377490 -0.325137   \n",
       "Standard Deviation  0.455841  6.245606  0.260468  0.498055  0.476962   \n",
       "Relative Coef Size  0.658884  0.009796  3.767767  0.757928 -0.681683   \n",
       "Odds Ratio          1.350326  1.063094  2.668141  1.458619  0.722429   \n",
       "\n",
       "                       age_3     age_4     age_5    race_2    race_3  \\\n",
       "Coefficients        0.432341  0.669456  1.047469 -0.804206 -0.487379   \n",
       "Standard Deviation  0.409085  0.409210  0.318211  0.303916  0.128765   \n",
       "Relative Coef Size  1.056850  1.635973  3.291746 -2.646148 -3.785013   \n",
       "Odds Ratio          1.540861  1.953175  2.850428  0.447443  0.614234   \n",
       "\n",
       "                      race_4    race_5    race_6    race_7  health_2.0  \\\n",
       "Coefficients       -0.666179 -1.028038 -0.430177 -0.686019    0.165227   \n",
       "Standard Deviation  0.072783  0.186826  0.205942  0.355863    0.472992   \n",
       "Relative Coef Size -9.152921 -5.502659 -2.088828 -1.927759    0.349323   \n",
       "Odds Ratio          0.513667  0.357708  0.650394  0.503577    1.179661   \n",
       "\n",
       "                    health_3.0  health_4.0  \n",
       "Coefficients          0.227144    0.372580  \n",
       "Standard Deviation    0.461761    0.414585  \n",
       "Relative Coef Size    0.491908    0.898681  \n",
       "Odds Ratio            1.255010    1.451474  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Results = pd.DataFrame([coef_list,std_list,standardize, OR], index = ['Coefficients','Standard Deviation','Relative Coef Size','Odds Ratio'], \n",
    "            columns = ['AMHTXND2','WHODASC2','SMIPP_U','AMDELT','IRSEX','age_3','age_4','age_5','race_2','race_3','race_4','race_5','race_6','race_7',\n",
    "                                                    'health_2.0','health_3.0','health_4.0'])\n",
    "Model_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMHTXND2</th>\n",
       "      <th>WHODASC2</th>\n",
       "      <th>SMIPP_U</th>\n",
       "      <th>AMDELT</th>\n",
       "      <th>IRSEX</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_4</th>\n",
       "      <th>age_5</th>\n",
       "      <th>race_2</th>\n",
       "      <th>race_3</th>\n",
       "      <th>race_4</th>\n",
       "      <th>race_5</th>\n",
       "      <th>race_6</th>\n",
       "      <th>race_7</th>\n",
       "      <th>health_2.0</th>\n",
       "      <th>health_3.0</th>\n",
       "      <th>health_4.0</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Coefficients</th>\n",
       "      <td>0.300346</td>\n",
       "      <td>0.061183</td>\n",
       "      <td>0.981382</td>\n",
       "      <td>0.377490</td>\n",
       "      <td>-0.325137</td>\n",
       "      <td>0.432341</td>\n",
       "      <td>0.669456</td>\n",
       "      <td>1.047469</td>\n",
       "      <td>-0.804206</td>\n",
       "      <td>-0.487379</td>\n",
       "      <td>-0.666179</td>\n",
       "      <td>-1.028038</td>\n",
       "      <td>-0.430177</td>\n",
       "      <td>-0.686019</td>\n",
       "      <td>0.165227</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.372580</td>\n",
       "      <td>-1.726714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Deviation</th>\n",
       "      <td>0.455841</td>\n",
       "      <td>6.245606</td>\n",
       "      <td>0.260468</td>\n",
       "      <td>0.498055</td>\n",
       "      <td>0.476962</td>\n",
       "      <td>0.409085</td>\n",
       "      <td>0.409210</td>\n",
       "      <td>0.318211</td>\n",
       "      <td>0.303916</td>\n",
       "      <td>0.128765</td>\n",
       "      <td>0.072783</td>\n",
       "      <td>0.186826</td>\n",
       "      <td>0.205942</td>\n",
       "      <td>0.355863</td>\n",
       "      <td>0.472992</td>\n",
       "      <td>0.461761</td>\n",
       "      <td>0.414585</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relative Coef Size</th>\n",
       "      <td>0.658884</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>3.767767</td>\n",
       "      <td>0.757928</td>\n",
       "      <td>-0.681683</td>\n",
       "      <td>1.056850</td>\n",
       "      <td>1.635973</td>\n",
       "      <td>3.291746</td>\n",
       "      <td>-2.646148</td>\n",
       "      <td>-3.785013</td>\n",
       "      <td>-9.152921</td>\n",
       "      <td>-5.502659</td>\n",
       "      <td>-2.088828</td>\n",
       "      <td>-1.927759</td>\n",
       "      <td>0.349323</td>\n",
       "      <td>0.491908</td>\n",
       "      <td>0.898681</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Odds Ratio</th>\n",
       "      <td>1.350326</td>\n",
       "      <td>1.063094</td>\n",
       "      <td>2.668141</td>\n",
       "      <td>1.458619</td>\n",
       "      <td>0.722429</td>\n",
       "      <td>1.540861</td>\n",
       "      <td>1.953175</td>\n",
       "      <td>2.850428</td>\n",
       "      <td>0.447443</td>\n",
       "      <td>0.614234</td>\n",
       "      <td>0.513667</td>\n",
       "      <td>0.357708</td>\n",
       "      <td>0.650394</td>\n",
       "      <td>0.503577</td>\n",
       "      <td>1.179661</td>\n",
       "      <td>1.255010</td>\n",
       "      <td>1.451474</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    AMHTXND2  WHODASC2   SMIPP_U    AMDELT     IRSEX  \\\n",
       "Coefficients        0.300346  0.061183  0.981382  0.377490 -0.325137   \n",
       "Standard Deviation  0.455841  6.245606  0.260468  0.498055  0.476962   \n",
       "Relative Coef Size  0.658884  0.009796  3.767767  0.757928 -0.681683   \n",
       "Odds Ratio          1.350326  1.063094  2.668141  1.458619  0.722429   \n",
       "\n",
       "                       age_3     age_4     age_5    race_2    race_3  \\\n",
       "Coefficients        0.432341  0.669456  1.047469 -0.804206 -0.487379   \n",
       "Standard Deviation  0.409085  0.409210  0.318211  0.303916  0.128765   \n",
       "Relative Coef Size  1.056850  1.635973  3.291746 -2.646148 -3.785013   \n",
       "Odds Ratio          1.540861  1.953175  2.850428  0.447443  0.614234   \n",
       "\n",
       "                      race_4    race_5    race_6    race_7  health_2.0  \\\n",
       "Coefficients       -0.666179 -1.028038 -0.430177 -0.686019    0.165227   \n",
       "Standard Deviation  0.072783  0.186826  0.205942  0.355863    0.472992   \n",
       "Relative Coef Size -9.152921 -5.502659 -2.088828 -1.927759    0.349323   \n",
       "Odds Ratio          0.513667  0.357708  0.650394  0.503577    1.179661   \n",
       "\n",
       "                    health_3.0  health_4.0  Intercept  \n",
       "Coefficients          0.227144    0.372580  -1.726714  \n",
       "Standard Deviation    0.461761    0.414585   0.000000  \n",
       "Relative Coef Size    0.491908    0.898681   0.000000  \n",
       "Odds Ratio            1.255010    1.451474   0.000000  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#include intercept term in table output\n",
    "inter = clf.intercept_.tolist()[0]\n",
    "Model_Results['Intercept'] = [inter,0,0,0]\n",
    "Model_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficients</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Relative Coef Size</th>\n",
       "      <th>Odds Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>race_4</th>\n",
       "      <td>-0.666179</td>\n",
       "      <td>0.072783</td>\n",
       "      <td>-9.152921</td>\n",
       "      <td>0.513667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_5</th>\n",
       "      <td>-1.028038</td>\n",
       "      <td>0.186826</td>\n",
       "      <td>-5.502659</td>\n",
       "      <td>0.357708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_3</th>\n",
       "      <td>-0.487379</td>\n",
       "      <td>0.128765</td>\n",
       "      <td>-3.785013</td>\n",
       "      <td>0.614234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_2</th>\n",
       "      <td>-0.804206</td>\n",
       "      <td>0.303916</td>\n",
       "      <td>-2.646148</td>\n",
       "      <td>0.447443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_6</th>\n",
       "      <td>-0.430177</td>\n",
       "      <td>0.205942</td>\n",
       "      <td>-2.088828</td>\n",
       "      <td>0.650394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_7</th>\n",
       "      <td>-0.686019</td>\n",
       "      <td>0.355863</td>\n",
       "      <td>-1.927759</td>\n",
       "      <td>0.503577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRSEX</th>\n",
       "      <td>-0.325137</td>\n",
       "      <td>0.476962</td>\n",
       "      <td>-0.681683</td>\n",
       "      <td>0.722429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-1.726714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHODASC2</th>\n",
       "      <td>0.061183</td>\n",
       "      <td>6.245606</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>1.063094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_2.0</th>\n",
       "      <td>0.165227</td>\n",
       "      <td>0.472992</td>\n",
       "      <td>0.349323</td>\n",
       "      <td>1.179661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_3.0</th>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.461761</td>\n",
       "      <td>0.491908</td>\n",
       "      <td>1.255010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMHTXND2</th>\n",
       "      <td>0.300346</td>\n",
       "      <td>0.455841</td>\n",
       "      <td>0.658884</td>\n",
       "      <td>1.350326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMDELT</th>\n",
       "      <td>0.377490</td>\n",
       "      <td>0.498055</td>\n",
       "      <td>0.757928</td>\n",
       "      <td>1.458619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_4.0</th>\n",
       "      <td>0.372580</td>\n",
       "      <td>0.414585</td>\n",
       "      <td>0.898681</td>\n",
       "      <td>1.451474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_3</th>\n",
       "      <td>0.432341</td>\n",
       "      <td>0.409085</td>\n",
       "      <td>1.056850</td>\n",
       "      <td>1.540861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_4</th>\n",
       "      <td>0.669456</td>\n",
       "      <td>0.409210</td>\n",
       "      <td>1.635973</td>\n",
       "      <td>1.953175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_5</th>\n",
       "      <td>1.047469</td>\n",
       "      <td>0.318211</td>\n",
       "      <td>3.291746</td>\n",
       "      <td>2.850428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMIPP_U</th>\n",
       "      <td>0.981382</td>\n",
       "      <td>0.260468</td>\n",
       "      <td>3.767767</td>\n",
       "      <td>2.668141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coefficients  Standard Deviation  Relative Coef Size  Odds Ratio\n",
       "race_4         -0.666179            0.072783           -9.152921    0.513667\n",
       "race_5         -1.028038            0.186826           -5.502659    0.357708\n",
       "race_3         -0.487379            0.128765           -3.785013    0.614234\n",
       "race_2         -0.804206            0.303916           -2.646148    0.447443\n",
       "race_6         -0.430177            0.205942           -2.088828    0.650394\n",
       "race_7         -0.686019            0.355863           -1.927759    0.503577\n",
       "IRSEX          -0.325137            0.476962           -0.681683    0.722429\n",
       "Intercept      -1.726714            0.000000            0.000000    0.000000\n",
       "WHODASC2        0.061183            6.245606            0.009796    1.063094\n",
       "health_2.0      0.165227            0.472992            0.349323    1.179661\n",
       "health_3.0      0.227144            0.461761            0.491908    1.255010\n",
       "AMHTXND2        0.300346            0.455841            0.658884    1.350326\n",
       "AMDELT          0.377490            0.498055            0.757928    1.458619\n",
       "health_4.0      0.372580            0.414585            0.898681    1.451474\n",
       "age_3           0.432341            0.409085            1.056850    1.540861\n",
       "age_4           0.669456            0.409210            1.635973    1.953175\n",
       "age_5           1.047469            0.318211            3.291746    2.850428\n",
       "SMIPP_U         0.981382            0.260468            3.767767    2.668141"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Largest Relative Coefficients :\n",
    "m = Model_Results.copy().T\n",
    "m.sort_values('Relative Coef Size')\n",
    "#Race seems to be the most impactful variable by far, but if race_1 were in the model, it would likely be the highest coefficient\n",
    "#It is probably worth replacing some of the extra race terms by the race = White dummy variable (race_1)\n",
    "#All other race terms have a negative effect on the probablity of receiving treatment, so would help model dimensionality\n",
    "\n",
    "#After race, next most substanstial Coef Size is SMIPP_U, the predicted probability of serious mental illness\n",
    "#However, this information is likely the most difficult to obtain for replication, but could be implemented in a model for use by SAMHSA, the survey-maker.\n",
    "\n",
    "#Next most substantive are the dummy age variables. In a similar fashion to the race variables but in the opposite direction, all age categories\n",
    "#except for ages 18-25(age_2, age_1 is not included in my population sample of those experiencing serious psychological distress within past year)\n",
    "#have a positive effect on the probability of receiving treatment. \n",
    "\n",
    "#IRSEX, AMHTXND2, and AMDELT all have similar coefficient effects with 1.3-1.5 odds ratios in one direction or the other\n",
    "\n",
    "#Health is least powerful predictor of the categoricals I included in my full model. However, all dummy terms except for health_1.0 are positive,\n",
    "#so could be worth using health_1 instead of the other three to reduce dimensions.(health=excellent lowers the probability of the individual seeking treatment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Table can be used to view my model coeffecients including intercept \n",
    "Model_Coef = pd.DataFrame(pd.DataFrame(co).T.values, columns=['AMHTXND2','WHODASC2','SMIPP_U','AMDELT','IRSEX','age_3','age_4','age_5','race_2','race_3','race_4','race_5','race_6','race_7',\n",
    "                                                    'health_2.0','health_3.0','health_4.0','Intercept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I should try making the simplest models, predicting AMHTXRC3 ~ one var\n",
    "#and compare the prediction accuracy of this model to my full model. If the difference is not substantial, \n",
    "#I can effectively reduce the size of the model to something much more simple and easy to apply.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reduced Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I should probably start the model-fitting process with one parameter models at first in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 0.01}\n",
      "Accuracy on training data: 0.61\n",
      "Accuracy on test data:     0.60\n"
     ]
    }
   ],
   "source": [
    "#Faster one cell method for testing the model accuracy with different values of C\n",
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['AMHTXND2'], 'AMHTXRC3',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 0.1}\n",
      "Accuracy on training data: 0.57\n",
      "Accuracy on test data:     0.60\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['race_1'], 'AMHTXRC3',1)\n",
    "#simple model using race_1 as predictor gives best accuracy of all simple models using one race dummy var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 0.01}\n",
      "Accuracy on training data: 0.60\n",
      "Accuracy on test data:     0.59\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['age_2'], 'AMHTXRC3',1)\n",
    "#simple model using age_2 as predictor gives best accuracy of all simple models using one age dummy var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 0.01}\n",
      "Accuracy on training data: 0.58\n",
      "Accuracy on test data:     0.57\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['health_4.0'], 'AMHTXRC3',1)\n",
    "#simple model using health_4.0 as predictor gives best accuracy of all simple models using one health dummy var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 0.01}\n",
      "Accuracy on training data: 0.56\n",
      "Accuracy on test data:     0.55\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['IRSEX'], 'AMHTXRC3',1)\n",
    "#not extremely predictive on its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 0.01}\n",
      "Accuracy on training data: 0.62\n",
      "Accuracy on test data:     0.63\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['AMDELT'], 'AMHTXRC3',1)\n",
    "#This is actually pretty good on its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 0.1}\n",
      "Accuracy on training data: 0.65\n",
      "Accuracy on test data:     0.65\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['WHODASC2'], 'AMHTXRC3',1)\n",
    "#Mental distress measure is an appropriately good predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 10}\n",
      "Accuracy on training data: 0.65\n",
      "Accuracy on test data:     0.66\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['SMIPP_U'], 'AMHTXRC3',1)\n",
    "#Predicted Probability of Mental Illness is similarly predictive of receiving treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 0.01}\n",
      "Accuracy on training data: 0.63\n",
      "Accuracy on test data:     0.66\n"
     ]
    }
   ],
   "source": [
    "#Two parameter models\n",
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['race_1','age_2'], 'AMHTXRC3',1)\n",
    "#Best params to pair with race_1 have been whodas-67, smipp-66, amdelt-64, age-64, irsex-61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 10}\n",
      "Accuracy on training data: 0.66\n",
      "Accuracy on test data:     0.66\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['SMIPP_U','AMDELT'], 'AMHTXRC3',1)\n",
    "#Best params to pair with SMIPP_U are WHODASC2 , race, age, irsex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 10}\n",
      "Accuracy on training data: 0.66\n",
      "Accuracy on test data:     0.67\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['age_2','SMIPP_U'], 'AMHTXRC3',1)\n",
    "#Best params to pair with age_2 have been SMIPP_U, WHODASC2, AMDELT, race_1, IRSEX in that order compared to 60% accuracy alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 0.01}\n",
      "Accuracy on training data: 0.66\n",
      "Accuracy on test data:     0.67\n"
     ]
    }
   ],
   "source": [
    "#Three parameter models\n",
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['SMIPP_U','WHODASC2','AMDELT','AMHTXND2'], 'AMHTXRC3',1)\n",
    "#not gaining accuracy by adding AMDELT or AMHTXND2 to SMIPP_U and WHODASC2, suggesting possible collinearity between these vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 0.01}\n",
      "Accuracy on training data: 0.63\n",
      "Accuracy on test data:     0.64\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['age_2','race_1','IRSEX'], 'AMHTXRC3',1)\n",
    "#averaging around 64 percent accuracy with these vars, need to combine demographics with mental health information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 0.1}\n",
      "Accuracy on training data: 0.68\n",
      "Accuracy on test data:     0.70\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['age_2','race_1','SMIPP_U'], 'AMHTXRC3',1)\n",
    "#Getting around 68 or 69 percent accuracy with these params, best reduced model so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 0.1}\n",
      "Accuracy on training data: 0.67\n",
      "Accuracy on test data:     0.66\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['WHODASC2','race_1','SMIPP_U'], 'AMHTXRC3',1)\n",
    "#This is a little worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 10}\n",
      "Accuracy on training data: 0.68\n",
      "Accuracy on test data:     0.68\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['age_2','WHODASC2','SMIPP_U'], 'AMHTXRC3',1)\n",
    "#race seems to be performing a little better here than WHODASC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 0.01}\n",
      "Accuracy on training data: 0.65\n",
      "Accuracy on test data:     0.63\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['age_2','race_1','AMDELT'], 'AMHTXRC3',1)\n",
    "#AMDELT is not performing well with increased model size across the board, may not be a great predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 1}\n",
      "Accuracy on training data: 0.67\n",
      "Accuracy on test data:     0.68\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['WHODASC2','SMIPP_U','AMHTXND2','age_2',''], 'AMHTXRC3',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 0.01}\n",
      "Accuracy on training data: 0.65\n",
      "Accuracy on test data:     0.66\n"
     ]
    }
   ],
   "source": [
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['age_2','race_1','IRSEX','AMHTXND2'], 'AMHTXRC3',1)\n",
    "#I'm getting around 65 or 66 percent accuracy with this model\n",
    "#We are likely overfitting the data with any more than 4 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS {'C': 10}\n",
      "Accuracy on training data: 0.69\n",
      "Accuracy on test data:     0.70\n"
     ]
    }
   ],
   "source": [
    "#This is the full model reduced to 1 dummy var per categorical\n",
    "clf_l, Xtrain_l, ytrain_l, Xtest_l, ytest_l  = do_classify(LogisticRegression(), \n",
    "                                                           {\"C\": [0.01, 0.1, 1, 10, 100]}, \n",
    "                                                           data, ['age_2','race_1','health_1.0','SMIPP_U','AMDELT','WHODASC2','IRSEX','AMHTXND2'], 'AMHTXRC3',1)\n",
    "\n",
    "#This captures the same accuracy as the full model with all dummy vars\n",
    "\n",
    "#Is there a way for me to show that the remainder of the probability that someone seeks mental health treatment is explained by unobserved variables\n",
    "#such as the specific mental illness? NO because they haven't all received treatment so we can't tell. \n",
    "\n",
    "#The best that we can do is find common predictors that increase our probability of accurately predicting whether someone receives treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Do you think that I should have my final reduced model exclude survey-only variables?\n",
    "#Or present a few different models with high accuracy(relatively speaking)?\n",
    "#It seems like I can only get up to about 64-65% accuracy without using Mental Health Diagnostic variables from the survey\n",
    "#  That is the model using age_2 and race_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(data[['SMIPP_U','age_2','race_1']].values, \n",
    "                                              (data['AMHTXRC3'] == 1).values,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.675656493967\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(Xlr,ylr)\n",
    "print (accuracy_score(clf.predict(Xtestlr),ytestlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C value: 0.1\n",
      "Average Score using this C: 0.686863905325\n"
     ]
    }
   ],
   "source": [
    "#the grid of parameters to search over\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "max_score = 0\n",
    "\n",
    "for C in Cs :\n",
    "    clf = LogisticRegression(C=C)\n",
    "    score = cv_score(clf, Xlr, ylr)\n",
    "    \n",
    "    if score > max_score :\n",
    "        max_score = score\n",
    "        bestC = C\n",
    "        \n",
    "print(\"Best C value:\",bestC)\n",
    "print(\"Average Score using this C:\",max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67707594038325059"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfBest = LogisticRegression(C=bestC)\n",
    "clfBest.fit(Xlr,ylr)\n",
    "ypred = clfBest.predict(Xtestlr)\n",
    "accuracy_score(ypred,ytestlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Need to fix this output code, shouldn't be a problem\n",
    "#coef_list = clf.coef_.tolist()[0]\n",
    "#std_list = list(s)\n",
    "#standardize = [0,1,2]\n",
    "#for i in range(len(standardize)) :\n",
    "#    standardize[i] = coef_list[i]/std_list[i]\n",
    "#OR = np.exp(coef_list).tolist()\n",
    "#Model_Results = pd.DataFrame([coef_list,std_list,standardize, OR], index = ['Coefficients','Standard Deviation','Relative Coef Size','Odds Ratio'], \n",
    "#            columns = ['SMIPP_U','age_2','race_1'])\n",
    "#Model_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.545646422770245, 0.5323616668845331, 2.181518387119971]"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_list = clf.coef_.tolist()[0]\n",
    "OR = np.exp(coef_list).tolist()\n",
    "OR\n",
    "#This can be interpreted as : \n",
    "\n",
    "#Someone who is within ages 18-25 is about half as likely to receive mental health treatment for their psychological distress than someone older\n",
    "#To put it another way, 1.88 people who are older than that receive treatment for each 18-25 year old who does\n",
    "#1/.53236 = 1.88 \n",
    "\n",
    "#An adult who is white is more than twice as likely to seek treatment than an adult of another race\n",
    "#2.18 white adults receive treatment for mental health disorders for each 1 person of another race who does.\n",
    "\n",
    "#SMIPP_U is a little more difficult to interpret, but for each .10 higher that SMIPP_U is (10% more likely to have serious mental illness),\n",
    "#that person's odds of receiving treatment increase by 1.35 to 1. So 13.5 adults with a 100% predicted probability of serious mental illness\n",
    "#receive mental health treatment for each person with a 0% predicted probability of mental illness who receives treatment.\n",
    "\n",
    "#Trying to understand 70% accuracy plateau : \n",
    "#Other 30% could possibly be explained by individual mental disorder, or could be the percentage of adults \n",
    "#experiencing serious psychological distress within the past year who don't have a mental health disorder\n",
    "\n",
    "#What would the prediction accuracy of the null model be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMIPP_U</th>\n",
       "      <th>age_2</th>\n",
       "      <th>race_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Coefficients</th>\n",
       "      <td>2.606065</td>\n",
       "      <td>-0.630432</td>\n",
       "      <td>0.780021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Deviation</th>\n",
       "      <td>0.260468</td>\n",
       "      <td>0.498489</td>\n",
       "      <td>0.478390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relative Coef Size</th>\n",
       "      <td>10.005328</td>\n",
       "      <td>-1.264686</td>\n",
       "      <td>1.630512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Odds Ratio</th>\n",
       "      <td>13.545646</td>\n",
       "      <td>0.532362</td>\n",
       "      <td>2.181518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      SMIPP_U     age_2    race_1\n",
       "Coefficients         2.606065 -0.630432  0.780021\n",
       "Standard Deviation   0.260468  0.498489  0.478390\n",
       "Relative Coef Size  10.005328 -1.264686  1.630512\n",
       "Odds Ratio          13.545646  0.532362  2.181518"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = data[['SMIPP_U','age_2','race_1']].std()\n",
    "std_list = list(s)\n",
    "standardize = [0,1,2]\n",
    "for i in range(len(standardize)) :\n",
    "    standardize[i] = coef_list[i]/std_list[i]\n",
    "Model_Results = pd.DataFrame([coef_list,std_list,standardize, OR], index = ['Coefficients','Standard Deviation','Relative Coef Size','Odds Ratio'],\n",
    "                             columns = ['SMIPP_U','age_2','race_1'])\n",
    "Model_Results\n",
    "\n",
    "#There are of course many factors that play into whether or not someone receives mental health treatment: values and biases and misconceptions. \n",
    "#These are things that are difficult to measure and put into numerical form in a useful manner for the purposes of modeling. \n",
    "#However using only simple demographics and some diagnostic information from the NSDUH, I have been able to predict with 70% accuracy whether or not\n",
    "#an adult experiencing serious psychological distress at any point during the last year has received treatment for the distress affecting their life.\n",
    "\n",
    "#About 45% of adults experiencing serious psychological distress during the last year received treatment for their mental health\n",
    "#Just knowing whether or not an adult is white and whether or not they are between the ages of 18 and 25 account can allow you to predict \n",
    "#whether or not the adult in question will receive treatment with 20% better accuracy than the null model. (~65% accuracy > 45% accuracy for all predictions of 1)\n",
    "\n",
    "#The model tops out in terms of predictive power at about 70% accuracy. This is most easily accomplished by adding only one more term, SMIPP_U to the model.\n",
    "#This is the predicted probability of serious mental illness, now calculated as part of the NSDUH survey annually. \n",
    "#This information couldn't be obtained outside of the context of the survey, so would only be useful for SAMHSA or a third party familiar with the NSDUH.\n",
    "#As far as making a model that is easy to use outside of organized medicine goes, the most accurate model would be \n",
    "#AMHTXRC3 ~ age_2 + race_1 + IRSEX + AMHTXND2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
